---
title: 'Испытания: это измерения'
---

Испытания считаются важнейшим видом свидетельств успешности/качества.
Испытания --- это измерения с целью получить обоснование претензии. Как
и любое измерение, это действие, требующее ресурсов и времени. Даже
«восприятие», как отмечалось в «Системном мышлении» --- это действие,
это не пассивная «фильтрация сигналов из окружающего мира»:

1.  Планирование измерения, оно не происходит «случайно само». Нужен
    выбор того, что измерять (причинно-следственные связи с целью:
    инженерное обоснование) и тут важно сгенерировать достаточное число
    альтернатив, выбор того, как измерять (тоже из достаточного числа
    альтернатив, с которыми хорошо бы быть знакомым), планирование
    ресурсов измерения и обоснования, обеспечение их выделения
    (координационная работа). Это всё требует удержания внимания (в
    инженерии это означает, что всё это записывается, а не происходит «в
    уме»).
2.  Подготовка измерения. Даже если речь идёт о простейшем «внешнем
    осмотре», это означает, что нужно физически привести во
    взаимодействие измеряемый объект и измерительный прибор, то есть
    как-то подтащить измеряемый объект к проводящему наблюдение
    инспектору или подвести инспектора к измеряемому объекту. Это время
    и ресурс как наличия и логистики от места изготовления к месту
    осмотра объекта, так и наличия и логистики от его текущего места к
    месту осмотра инспектора (без приборов при «внешнем осмотре», или с
    приборами. Впрочем, сейчас и при внешнем осмотре вполне могут
    фотографировать, то есть и тут приборы).
3.  Взаимодействие в ходе измерения. И хотя в случае квантовых измерений
    шаг по выводу информации измерения за пределы датчика рассматривают
    отдельно (бит измеряется и копируется; кубит измеряется, но не
    копируется), будем считать, что речь идёт о классическом в смысле
    физики измерении с результатом в битах. И этот результат тоже как-то
    документируется. И если речь идёт о статистических результатах, то
    этих взаимодействий (и подготовок к ним) в измерениях может быть
    множество, а сами измерения могут занимать и фемтосекунды, и годы.
4.  Принятие решений на основе результатов измерения. Если это
    эксперимент в рамках попперианского понимания науки, то он
    определяет выбор той теории, которая будет считаться
    фальсифицированной/опровергнутой (эксперимент как измерение какой-то
    характеристики при определённых условиях производится для
    опровержения тех теорий, которые хуже предсказывают результаты
    измерения)^[Дэвид Дойч, «Начало бесконечности.
    Объяснения, которые меняют мир»,], если это
    инженерное обоснование качества/успешности системы, то результат
    обоснования: удовлетворение или неудовлетворение претензии/claim.

Есть огромное число разных вариантов проведения испытаний, которые
породили обширную терминологию, связанную главным образом с тем, как
готовятся измерения и с особенностями проведения измерений (список тут
абсолютно неполный, это просто примеры того, что часто встречается в
разговорах об испытаниях как лучшем источнике свидетельств для
аргументирования претензий на успешность/качество системы):

-   **Мониторинг** --- это «постоянно идущее в ходе эксплуатации
    испытание», входные характеристики окружения при этом задаются
    эксплуатационной средой, а результаты оцениваются для обоснования
    заключения об успешности эксплуатации, или о необходимости ремонта
    («ремонт по состоянию», скажем, акустический датчик на трубе слушает
    шорох песчинок в протекающей по трубе с какими-то отложениями на
    стенках нефти, на основе анализа этого шороха делается вывод о
    работоспособности трубы и необходимости её чистки или даже замены),
    или о коррекции эксплуатационного режима (цифровой двойник). Если
    речь идёт о подобном в какой-то определённый момент (например, в
    момент старта работы), то говорят не о «мониторинге», а
    самотестировании/самодиагностике.
-   **Всевозможные тестируемые объекты**
    («железо»^[<https://en.wikipedia.org/wiki/Hardware-in-the-loop_simulation>],
    софт, модели, люди, системы) **in-the-loop**, причём loop тут
    понимается как симулятор надсистемы (окружение), в которую
    помещается тестируемый объект, на входы-выходы которого подаются
    нужные для полноценного тестирования сигналы (для «железа»), нужные
    значения на API (для софта), нужные параметры (для модели, чаще
    всего это компьютерная модель), нужные стимулы (для людей), нужные
    изменения в среде (для систем), а потом считывается реакция и
    происходит её анализ. Этот самый loop иногда называют «стендом».
    Этот цикл «предъявить системное окружение с какими-то
    характеристиками, получить отклик тестируемой системы» происходит в
    случае «стенда» чаще всего в разы дешевле и быстрее, чем в реальной
    жизни, где нужно долго ждать, пока встретятся какие-нибудь редкие
    сочетания входных параметров. Скажем, если у вас
    hardware-in-the-loop (компьютер какого-нибудь гаджета с его
    прошивкой), то вы можете подавать на вход самые разные значения,
    якобы получаемые от датчиков этого гаджета, но на самом деле
    генерируемые «стендом» и смотреть на отклик так же быстро (не
    глазами, а считывая значения, выдаваемые компьютером гаджета для
    актуаторов --- это иногда моторчики, иногда дисплеи, иногда что-то
    ещё). Если бы вы помещали этот гаджет вместе с датчиками в какую-то
    реальную среду и делали каждый раз реальный замер (например, не
    подав сигнал датчика температуры «как будто у нас -30°C», а реально
    прицепив датчик и охладив его до нужной температуры, то это было бы
    в разы и разы медленней и дороже.
-   **Регрессионное тестирование** --- это повторное тестирование того,
    что уже вроде как тестировалось. Оно наиболее развито в программном
    обеспечении, где считается хорошим тоном прогонять все тесты в
    автоматическом режиме (это относительно дёшево) при любом изменении.
    Но и для «железа» оно тоже довольно часто. Скажем, вы тестируете
    тормозной путь, но поменяли шины. И опять тестируете на тормозной
    путь. Или поменяли бортовой компьютер, а не шины --- и всё равно
    тестируете. Повторный экзамен для людей часто не менее осмыслен:
    профессиональные ассоциации заставляют переэкзаменовываться каждые
    несколько лет, это как раз и есть регрессионное тестирование (при
    этом тесты ЕГЭ являются более-менее бессмысленными, и уже через пару
    лет после школы их мало кто сможет сдать повторно, поэтому вопрос о
    регрессионном тестировании «готовности к жизни» не поднимается, ЕГЭ
    имеет абсолютно другие цели, не связанные с готовностью школьников
    ко взрослой жизни).
-   **Юнит-тестирование** (тестирование отдельных модулей) и **системное
    тестирование** (системы в целом) и приёмочные/acceptance (хотя тут
    есть терминологическое противоречие с приёмкой/validation) испытания
    обсуждаются в плане необходимости соблюдения некоторого баланса
    между ними. Проблема в том, что из-за системного эффекта обоснование
    успешности в работе отдельных модулей не гарантирует успешности
    работы системы в целом, и тем более работы надсистемы, да ещё и в
    необходимом разбросе параметров условий эксплуатации. Но заведомо
    неуспешный модуль вполне может вести к заведомой неуспешности
    системы, и его довольно легко обнаружить. Системное же тестирование
    крайне дорого. Вопрос в том, сколько внимания при фиксированном
    бюджете на тестирование уделять испытаниям модулей, и сколько
    испытаниям системы. В программной инженерии договорились до того,
    что ввели TDD (Test-Driven
    Development)^[<https://en.wikipedia.org/wiki/Test-driven_development>],
    когда вместо требований по итогам моделирования use case сразу
    пишется «испытательный стенд», который проверяет результаты работы
    одного модуля/юнита (unit-testing). Утверждалось, что это резко
    поднимет качество и скорость разработки программ. И действительно,
    появилось много обзоров и отдельных
    исследований^[<https://www.researchgate.net/publication/327395450_Evaluating_the_effectiveness_of_test_driven_development_Advantages_and_pitfalls>,
    <https://beei.org/index.php/EEI/article/view/2533/1599> и множество
    подобных.], в которых делались утверждения, что «всё
    стало лучше», но вот надёжного инженерного обоснования так и не
    получено (к методам этих исследований очень много вопросов), так что
    практика TDD довольно популярна в разработке программ, но нельзя
    сказать, что она стала повсеместной, показав драматические
    преимущества перед разработкой тестов после разработки основной
    программы. Попутно выяснилось много интересного: независимо
    написанные тесты оказались качеством не лучше, чем написанные самими
    разработчиками модуля.
-   **Автоматизированное
    тестирование**^[<https://en.wikipedia.org/wiki/Test_automation>]
    в противовес **ручному тестированию**. Если понятно, какие
    требования (но их сначала нужно составить и документировать!), то
    можно поручить какой-нибудь программе составить программу
    испытаний/тестирования (набор тестов/измерений), а потом «прогнать
    тесты/замеры». И получить на выходе список тестов/замеров, которые
    будут «неприятным сюрпризом». Проблема в том, что для получения
    ошибки может быть задействован довольно хитрый и длинный сценарий, и
    простой случайный перебор сочетаний входных параметров не даст
    выявленной ошибки. Если тестировщик думает о том, какую ошибку мог
    бы совершить разработчик, то он действует не случайным перебором, а
    целенаправленно --- и находит ошибку. Но человек-тестировщик крайне
    медлен и крайне дорог. Проще добавить вычислительной мощности и
    поручить тестирование алгоритму. Но чем больше становится система,
    тем трудней в ней найти ошибку методом случайного тыка. Так что
    ручное (особенно в рамках TDD) и автоматизированное тестирование
    соревнуются, и на сегодня победителей в этом соревновании нет (в
    инженерии всё будет результатом прохождения развилок, и выбор
    способа тестирования тоже будет рациональным выбором варианта,
    соответствующего конкретным обстоятельствам вашего проекта, и ещё
    определённому моменту времени в проекте).
-   **Инженерия** **хаосом/chaos**
    **engineering**^[<https://en.wikipedia.org/wiki/Chaos_engineering>]
    как проведение испытаний путём планового отключения каких-то модулей
    на работающей системе и проверки того, как это влияет на
    работоспособность системы. Отличие от «аварии» только в том, что это
    отключение происходит в заранее известный момент времени, и
    известно, что именно выключается (поэтому есть шанс всё вернуть на
    место, если что-то пойдёт не так). Это очень жёсткий способ
    испытаний, в чем-то эквивалентный древним способам испытания мостов,
    когда под мостом стоит главный инженер и его команда, а по мосту
    движется первый грузовой поезд, да ещё и с максимальной загрузкой.
    Представьте, когда вам нужно по плану заглушить двигатель самолёта в
    полёте, и проверить, что самолёт нормально летит дальше на
    оставшихся двигателях. Или заклинить один из рулей и проверить, что
    остальных рулей хватает, чтобы лететь нормально. В случае
    программных систем это не выглядит так драматично, но представьте,
    если вам нужно оторвать интернет-соединение, за которым находятся
    три миллиона ваших клиентов --- сколько от них прилетит звонков,
    если что-то пойдёт не так? Какую ответственность вы почувствуете за
    их убытки? Но зато при инженерии хаосом вы будете уверены, что при
    всяких «неожиданностях» ничего особо неожиданного не произойдёт, «у
    нас отвалилось крыло, как пару месяцев назад на плановом отвале
    крыла, занимаемся определением причин поломки, но летим нормально,
    жалоб нет».
